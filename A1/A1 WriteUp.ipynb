{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given by the assignment\n",
    "def loadData():\n",
    "    with np.load('notMNIST.npz') as data :\n",
    "        Data, Target = data['images'], data['labels']\n",
    "        posClass = 2\n",
    "        negClass = 9\n",
    "        dataIndx = (Target==posClass) + (Target==negClass)\n",
    "        Data = Data[dataIndx]/255.\n",
    "        Target = Target[dataIndx].reshape(-1, 1)\n",
    "        Target[Target==posClass] = 1\n",
    "        Target[Target==negClass] = 0\n",
    "        np.random.seed(421)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data, Target = Data[randIndx], Target[randIndx]\n",
    "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
    "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
    "        testData, testTarget = Data[3600:], Target[3600:]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (3500, 28, 28)\tTraining tagets: (3500, 1)\n",
      "Validation Data: (100, 28, 28)\tValidation tagets: (100, 1)\n",
      "Testing Data: (145, 28, 28)\tTesting tagets:(145, 1)\n"
     ]
    }
   ],
   "source": [
    "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "print(f\"Training Data: {trainData.shape}\\tTraining tagets: {trainTarget.shape}\")\n",
    "print(f\"Validation Data: {validData.shape}\\tValidation tagets: {validTarget.shape}\")\n",
    "print(f\"Testing Data: {testData.shape}\\tTesting tagets:{testTarget.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(image, target):\n",
    "    plt.imshow(image, cmap=\"hot\")\n",
    "    plt.title('J' if target == 0 else 'C')\n",
    "    # targets are binary encoded 0 == 'J' and 1 == 'C'\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAPmklEQVR4nO3dcayd9V3H8c/X2rlYYNBVSgNVxkIMaBzoTWMCMSPIBIyWzUDWZUnVuUsMqMtYMoZGiokGF2FhmVlyN5qVZQNZGFIT1GIzxohxckEsxaJU7EZp18K6htKI0PbrH+dpctue8/uee57nnOe59/t+Jc0993zPc57vOT2f+5xzfs/z/MzdBWDx+7G2GwAwGYQdSIKwA0kQdiAJwg4kQdiBJAg7kARhx0Bm9riZ/V7bfaAZhB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsiHDCg0WCsKPkDEk/bLsJNIOwoy8z+zlJF0n6t7Z7QTMIO05hZn8paYukT7v799ruB80wzkEH5MCWHUjixye5MjNz/rosLNH/17GgfunSQvEXfilY+mhQXxLUu6z0zAXP+sGnB5Z27Zdee92tX63W23gzu1rSPeo961929ztLt19i5u8ceW1ow7Kgfjiqn1covhy99g4G9TODepe9UaidVl70b/tmWZI09Slpdmf/sI+8oTWzJZL+WtI1ki6WtM7MLh71/gCMV5131Wsk7XT3l9z9LUkPSFrbTFsAmlYn7OdKennO77ur605gZtNmNmtms3zvD7Snzhd0/T4XnJJnd5+RNCP1PrPXWB+AGups2XdLWj3n9/Mk7anXDoBxqRP2pyRdaGbvMbN3SPqwpM3NtAWgaSO/jXf3I2Z2s6R/VG/obaO7P99YZ+iEN+vewd11Fp7obiALxx8UavsGl2o9m+7+qKRH69wHgMlghzYgCcIOJEHYgSQIO5AEYQeSIOxAEgxkJhcdER4dUb48WsH1nxm+mVMs5AOijwT10mGs/1Jc8u7dg2uFYXa27EAWhB1IgrADSRB2IAnCDiRB2IEkGHpLLvprHw293Riu4ZND97K4RENvpeh9vrjkhkKtdLZftuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kEStWVzni1lcu6f2LK0/G9zghdLrKzpR9UJ+tZRmaZWKh7h+Y/AsrZK07IbBtTclHfWGZ3EFsLAQdiAJwg4kQdiBJAg7kARhB5Ig7EASHM+eXHS8euiuOgsv5nH26Hj2wbwwjl5HrbCb2S5Jh9R7zRxx96kmmgLQvCa27Fe4+2sN3A+AMeIzO5BE3bC7pC1m9rSZTfe7gZlNm9msmc1Obi98ACer+zb+MnffY2ZnS3rMzF5w9yfm3sDdZyTNSL0DYWquD8CIam3Z3X1P9XO/pIclrWmiKQDNGznsZrbMzE4/flnSByRtb6oxAM2q8zZ+paSHzez4/Xzd3f+hka7QmGhK5mik+4JoBb9+/fDNnGIxj6OfGdQPDqzU2nWhYOSwu/tLkt7XYC8AxoihNyAJwg4kQdiBJAg7kARhB5LgENdFru6UzGvDNTw4dC+nWshDb9GgZeFU0ZKkjwysfGHevQyHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMGUzYtc9HxHo8WHVwQ3eDV6/ZTWsJBfDTWmZJakrYOnZV72q+VFS9Ns/0jS20zZDORG2IEkCDuQBGEHkiDsQBKEHUiCsANJcDz7IhedSjr0QN07GH3q4m6rGZ0a0zKXzkFQ2uuBLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+yJQGks/HCx7TnTnV14zv2bSqHcs/mcOjL5sdK7/QcItu5ltNLP9ZrZ9znXLzewxM3ux+nnWiOsHMCHDvI3/iqSrT7ruVklb3f1CSVur3wF0WBh2d39C0slvOtZK2lRd3iTpuob7AtCwUT+zr3T3vZLk7nvN7OxBNzSzaUnTkjT4rFsAxm3sX9C5+4ykGal3wslxrw9Af6MOve0zs1WSVP3c31xLAMZh1LBvlrS+urxe0iPNtANgXMK38WZ2v6T3S1phZrsl3S7pTkkPmtnHJH1f0vXjbBJlSwu1aEz2pvDevz6vXk61UM8NH51RP3pcHypWN8+rlxMdK9RKn5PDsLv7ugGlK6NlAXQHu8sCSRB2IAnCDiRB2IEkCDuQBFM2LwKl5zSckrk0bidJb0Wvj4NB/cyg3lU1H9fflXcOX/abg2t1ptl+U9JRpmwGciPsQBKEHUiCsANJEHYgCcIOJEHYgSQ4lfQiMOqphSVJD9Vd+2J9CdXcI+SToy9ae5rtAdiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASi3WQNJW3C7XocHX9xu/XXPtCfQkdCerROPtrxertO+fVzAneGn3RIrbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEQh0kTSUaKy+Ns/9JeO9/OK9eTpX1JfQXxerGGvdcmpK5jnDLbmYbzWy/mW2fc90GM3vFzJ6t/l07pv4ANGSYt/FfkXR1n+s/5+6XVP8ebbYtAE0Lw+7uT0g6MIFeAIxRnS/objazbdXb/LMG3cjMps1s1sxmJzerHICTjRr2L0p6r6RLJO2VdNegG7r7jLtPuftUeao7AOM0UtjdfZ+7H3X3Y5K+JGlNs20BaNpIYTezVXN+/aCk7YNuC6AbwvnZzex+Se+XtELSPkm3V79fIskl7ZJ0o7vvjVbG/OyjWRbUD5dq7woWPhh9k/JGUD8tqHdVzcf1QDD/+rry4qVzw9eZB6A0P3u4R4S792v73hr9AGgBu8sCSRB2IAnCDiRB2IEkCDuQRNbjExeUWqcWvrvu2qNTLi9UNR/XLfUWLw1Bl4ZS62DLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eAaXDHaXyqaIl6cxS8Xd/Z37NnGIhH5RcGksvPmvqHbk92Bf2zLeXE41rWuYStuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7B0Q/cWNTi380WK1PLVwbCG/RErj7NHj+nyx+mfz7uVE0b4T48CWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGGbK5tWS7pN0jqRjkmbc/R4zWy7pbySdr97Bvze4+49K98WUzf3VmZJZkg6vLBR/EE3J/GZQX8j/Y6VpmYMpmR8PpmS+orz40nJ5bOPspSmbh9myH5F0i7tfJOmXJd1kZhdLulXSVne/UNLW6ncAHRWG3d33uvsz1eVDknZIOlfSWkmbqpttknTduJoEUN+8PrOb2fmSLpX0XUkr3X2v1PuDIOnsppsD0Jyhd3w2s9MkPSTpE+7+uln5M82c5aYlTUvScEsAGIehtuxmtlS9oH/N3b9ZXb3PzFZV9VWS9vdb1t1n3H3K3acIO9CeMOzW24TfK2mHu8+dE3SzpPXV5fWSHmm+PQBNGWbo7XJJ35H0nHpDb5J0m3qf2x+U9NOSvi/penc/ULqvrENv0amifzKoHwrqh7cUildFQ28Hg3p0yuUuKz224HG9Mxh6+79g8XI5HPAcVWnoLfzM7u5PavDH7Str9AVggtiDDkiCsANJEHYgCcIOJEHYgSQIO5BEp84THI1Ht6n0VzHqO6pH4+h3BHVd9T/RLQqCQz07rXQIq1QeS//z4pK/FoyjR6LTf7eBLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJBEez96kxXo8ezSOHo25RuPon/KPB7eYKdS6fKro0pTKUjyOHvU+uP6/wWnVVtRc87iOV4/UPZU0gEWAsANJEHYgCcIOJEHYgSQIO5AEYQeS6NTx7BcE9dLYZt3jh98d1N9XqP1psOwZ/xTc4MroePTzg3ppvLruOHo0Fh6NKJeWj46lj85Z/0K5fPpFA0vROHq070Rb4+h1sGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTCcXYzWy3pPknnqDc/+4y732NmGyR9XNKr1U1vc/dHS/f1LpXneP6GXxF0c2Oh9oNg2eihRiOvlxVq5wXLRqJR29eCemksPXrcdet1zjsfHK++7fRi+Y7Szg+SPluodfV49HEaZqeaI5JucfdnzOx0SU+b2WNV7XPu/lfjaw9AU8Kwu/teSXury4fMbIekc8fdGIBmzeszu5mdL+lSSd+trrrZzLaZ2UYzO2vAMtNmNmtmszVn1AFQw9BhN7PTJD0k6RPu/rqkL0p6r6RL1Nvy39VvOXefcfcpd5/6iQYaBjCaocJuZkvVC/rX3P2bkuTu+9z9qLsfk/QlSWvG1yaAusKwm5lJulfSDne/e871q+bc7IOStjffHoCmhKeSNrPLJX1H0nPqDb1J0m2S1qn3Ft4l7ZJ0Y/Vl3kCXmvm3C/UzwtNalw6X7NTRuovIk0H9t8rlD+0fWLrj4fKipaEzKT4MdWmhthiH1qTyqaSH+Tb+SUn9Fi6OqQPoFvagA5Ig7EAShB1IgrADSRB2IAnCDiQx0cHpJaukM0pHqYYOFmrRoZbRKZF3B/XSIbQ/DJYNTnmszeXyK/9arv9zofbl8qKPbynXg8X190G9znh2dBhqdPrwxTqWPiq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRHg8e6MrM3tV0vfmXLVC8XmS29LV3rral0Rvo2qyt59x95/qV5ho2E9Zudmsu0+11kBBV3vral8SvY1qUr3xNh5IgrADSbQd9pmW11/S1d662pdEb6OaSG+tfmYHMDltb9kBTAhhB5JoJexmdrWZ/aeZ7TSzW9voYRAz22Vmz5nZs2Y223IvG81sv5ltn3PdcjN7zMxerH72nWOvpd42mNkr1XP3rJld21Jvq83sW2a2w8yeN7M/qq5v9bkr9DWR523in9nNbImk/5J0lXpnjHhK0jp3/4+JNjKAme2SNOXure+AYWa/ot4k5ve5+89X131W0gF3v7P6Q3mWu3+6I71tkPRG29N4V7MVrZo7zbik6yT9tlp87gp93aAJPG9tbNnXSNrp7i+5+1uSHpC0toU+Os/dn5B04KSr10raVF3epN6LZeIG9NYJ7r7X3Z+pLh+SdHya8Vafu0JfE9FG2M+V9PKc33erW/O9u6QtZva0mU233UwfK49Ps1X9PLvlfk4WTuM9SSdNM96Z526U6c/raiPs/aaS6tL432Xu/ouSrpF0U/V2FcMZahrvSekzzXgnjDr9eV1thH23pNVzfj9P0p4W+ujL3fdUP/dLeljdm4p63/EZdKufg2dOnLAuTePdb5pxdeC5a3P68zbC/pSkC83sPWb2DkkfVnh61ckws2XVFycys2WSPqDuTUW9WdL66vJ6SY+02MsJujKN96BpxtXyc9f69OfuPvF/kq5V7xv5/5b0x230MKCvCyT9e/Xv+bZ7k3S/em/r3lbvHdHHJL1b0lZJL1Y/l3eot6+qN7X3NvWCtaql3i5X76PhNknPVv+ubfu5K/Q1keeN3WWBJNiDDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H8Zek2+R6u9UgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(trainData[0], trainTarget[0])\n",
    "plot(trainData[1], trainTarget[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(X, w, b):\n",
    "    # flatten X\n",
    "    if len(X.shape) == 3:\n",
    "        X = X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    # insert 1's at position 0 along the columns\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    \n",
    "    # insert b at the front of W\n",
    "    w = np.insert(w, 0, b, axis=0)\n",
    "    \n",
    "    return X, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    return X.dot(w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w, b, X, y):\n",
    "    y = y.reshape(-1)\n",
    "    y_pred = predict(w, b, X)\n",
    "    y_pred = np.vectorize(lambda z: 1 if z > 0 else 0)(y_pred)\n",
    "    return sum(y_pred == y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Linear Regression\n",
    "### 1. Loss Function and Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import mean_squared_error\\n\\nX = trainData\\ny = trainTarget\\nN = X.shape[0]\\nd = X.shape[1] * X.shape[2]\\n\\nw = np.random.random_sample(d)\\nb = np.random.random_sample(1)\\n\\ny_pred = predict(w_LS, b_LS, X)\\nprint(mean_squared_error(y, y_pred))\\nprint(MSE(w_LS, b_LS, X, y, 0))\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Error Loss\n",
    "def MSE(w, b, X, y, reg):\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = y.reshape(-1)\n",
    "    return np.square(X.dot(w) + b - y).mean() + reg * np.square(w).sum()\n",
    "\n",
    "def gradMSE(w, b, X, y, reg):\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = y.reshape(-1)\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    w_grad = 2.0/N * X.T.dot(X.dot(w) + b - y) + reg * w\n",
    "    b_grad = 2.0/N * np.sum(X.dot(w) + b - y)\n",
    "    return w_grad, b_grad\n",
    "\n",
    "# The below is a test for MSE Loss, which is correct (at least without the regulator)\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = trainData\n",
    "y = trainTarget\n",
    "N = X.shape[0]\n",
    "d = X.shape[1] * X.shape[2]\n",
    "\n",
    "w = np.random.random_sample(d)\n",
    "b = np.random.random_sample(1)\n",
    "\n",
    "y_pred = predict(w_LS, b_LS, X)\n",
    "print(mean_squared_error(y, y_pred))\n",
    "print(MSE(w_LS, b_LS, X, y, 0))\n",
    "\"\"\"\n",
    "\n",
    "#gradMSE(w, b, X, y, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE DOWN ANALYTICAL EXPRESSIONS OF LOSS AND GRADIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3226.8582\tTraining acc: 49.86%\n",
      "Training loss: 553.7878\tTraining acc: 49.89%\n",
      "Training loss: 165.0795\tTraining acc: 47.91%\n",
      "Training loss: 100.6087\tTraining acc: 45.46%\n",
      "Training loss: 83.4901\tTraining acc: 47.71%\n",
      "Training loss: 74.2352\tTraining acc: 48.23%\n",
      "Training loss: 67.0027\tTraining acc: 49.37%\n",
      "Training loss: 60.7965\tTraining acc: 49.60%\n",
      "Training loss: 55.3567\tTraining acc: 50.29%\n",
      "Training loss: 50.5559\tTraining acc: 50.74%\n",
      "Training loss: 46.3036\tTraining acc: 51.00%\n",
      "Training loss: 42.5265\tTraining acc: 51.14%\n",
      "Training loss: 39.1632\tTraining acc: 51.51%\n",
      "Training loss: 36.1614\tTraining acc: 51.51%\n",
      "Training loss: 33.4759\tTraining acc: 51.54%\n",
      "Training loss: 31.0680\tTraining acc: 52.14%\n",
      "Training loss: 28.9041\tTraining acc: 52.20%\n",
      "Training loss: 26.9550\tTraining acc: 52.31%\n",
      "Training loss: 25.1954\tTraining acc: 52.60%\n",
      "Training loss: 23.6032\tTraining acc: 53.06%\n",
      "Training loss: 22.1595\tTraining acc: 53.40%\n",
      "Training loss: 20.8472\tTraining acc: 53.66%\n",
      "Training loss: 19.6520\tTraining acc: 53.71%\n",
      "Training loss: 18.5609\tTraining acc: 53.89%\n",
      "Training loss: 17.5628\tTraining acc: 54.29%\n",
      "Training loss: 16.6477\tTraining acc: 54.51%\n",
      "Training loss: 15.8071\tTraining acc: 54.69%\n",
      "Training loss: 15.0333\tTraining acc: 54.83%\n",
      "Training loss: 14.3195\tTraining acc: 55.14%\n",
      "Training loss: 13.6599\tTraining acc: 55.34%\n",
      "Training loss: 13.0491\tTraining acc: 55.34%\n",
      "Training loss: 12.4825\tTraining acc: 55.57%\n",
      "Training loss: 11.9560\tTraining acc: 55.60%\n",
      "Training loss: 11.4659\tTraining acc: 55.77%\n",
      "Training loss: 11.0088\tTraining acc: 56.00%\n",
      "Training loss: 10.5819\tTraining acc: 56.23%\n",
      "Training loss: 10.1825\tTraining acc: 56.29%\n",
      "Training loss: 9.8083\tTraining acc: 56.69%\n",
      "Training loss: 9.4572\tTraining acc: 56.86%\n",
      "Training loss: 9.1272\tTraining acc: 56.91%\n",
      "Training loss: 8.8168\tTraining acc: 56.89%\n",
      "Training loss: 8.5242\tTraining acc: 57.20%\n",
      "Training loss: 8.2482\tTraining acc: 57.43%\n",
      "Training loss: 7.9875\tTraining acc: 57.46%\n",
      "Training loss: 7.7410\tTraining acc: 57.51%\n",
      "Training loss: 7.5076\tTraining acc: 57.60%\n",
      "Training loss: 7.2863\tTraining acc: 57.89%\n",
      "Training loss: 7.0764\tTraining acc: 58.03%\n",
      "Training loss: 6.8770\tTraining acc: 58.31%\n",
      "Training loss: 6.6874\tTraining acc: 58.43%\n",
      "Training loss: 6.5069\tTraining acc: 58.40%\n",
      "Training loss: 6.3350\tTraining acc: 58.49%\n",
      "Training loss: 6.1711\tTraining acc: 58.54%\n",
      "Training loss: 6.0147\tTraining acc: 58.77%\n",
      "Training loss: 5.8654\tTraining acc: 58.89%\n",
      "Training loss: 5.7226\tTraining acc: 59.09%\n",
      "Training loss: 5.5861\tTraining acc: 59.11%\n",
      "Training loss: 5.4554\tTraining acc: 59.20%\n",
      "Training loss: 5.3301\tTraining acc: 59.29%\n",
      "Training loss: 5.2101\tTraining acc: 59.54%\n",
      "Training loss: 5.0949\tTraining acc: 59.54%\n",
      "Training loss: 4.9844\tTraining acc: 59.51%\n",
      "Training loss: 4.8782\tTraining acc: 59.66%\n",
      "Training loss: 4.7761\tTraining acc: 59.69%\n",
      "Training loss: 4.6779\tTraining acc: 59.74%\n",
      "Training loss: 4.5835\tTraining acc: 59.89%\n",
      "Training loss: 4.4925\tTraining acc: 59.89%\n",
      "Training loss: 4.4049\tTraining acc: 60.09%\n",
      "Training loss: 4.3204\tTraining acc: 60.29%\n",
      "Training loss: 4.2389\tTraining acc: 60.31%\n",
      "Training loss: 4.1603\tTraining acc: 60.20%\n",
      "Training loss: 4.0844\tTraining acc: 60.17%\n",
      "Training loss: 4.0111\tTraining acc: 60.20%\n",
      "Training loss: 3.9403\tTraining acc: 60.31%\n",
      "Training loss: 3.8718\tTraining acc: 60.34%\n",
      "Training loss: 3.8056\tTraining acc: 60.34%\n",
      "Training loss: 3.7415\tTraining acc: 60.46%\n",
      "Training loss: 3.6794\tTraining acc: 60.34%\n",
      "Training loss: 3.6193\tTraining acc: 60.34%\n",
      "Training loss: 3.5611\tTraining acc: 60.40%\n",
      "Training loss: 3.5047\tTraining acc: 60.43%\n",
      "Training loss: 3.4500\tTraining acc: 60.49%\n",
      "Training loss: 3.3969\tTraining acc: 60.43%\n",
      "Training loss: 3.3454\tTraining acc: 60.46%\n",
      "Training loss: 3.2954\tTraining acc: 60.46%\n",
      "Training loss: 3.2468\tTraining acc: 60.57%\n",
      "Training loss: 3.1997\tTraining acc: 60.63%\n",
      "Training loss: 3.1538\tTraining acc: 60.74%\n",
      "Training loss: 3.1093\tTraining acc: 60.74%\n",
      "Training loss: 3.0659\tTraining acc: 60.86%\n",
      "Training loss: 3.0238\tTraining acc: 60.91%\n",
      "Training loss: 2.9828\tTraining acc: 60.97%\n",
      "Training loss: 2.9429\tTraining acc: 61.11%\n",
      "Training loss: 2.9040\tTraining acc: 61.17%\n",
      "Training loss: 2.8662\tTraining acc: 61.20%\n",
      "Training loss: 2.8293\tTraining acc: 61.29%\n",
      "Training loss: 2.7934\tTraining acc: 61.31%\n",
      "Training loss: 2.7584\tTraining acc: 61.43%\n",
      "Training loss: 2.7242\tTraining acc: 61.43%\n",
      "Training loss: 2.6909\tTraining acc: 61.43%\n",
      "Training loss: 2.6584\tTraining acc: 61.54%\n",
      "Training loss: 2.6267\tTraining acc: 61.74%\n",
      "Training loss: 2.5958\tTraining acc: 61.77%\n",
      "Training loss: 2.5656\tTraining acc: 61.89%\n",
      "Training loss: 2.5361\tTraining acc: 61.83%\n",
      "Training loss: 2.5073\tTraining acc: 61.91%\n",
      "Training loss: 2.4792\tTraining acc: 61.91%\n",
      "Training loss: 2.4517\tTraining acc: 61.97%\n",
      "Training loss: 2.4248\tTraining acc: 62.06%\n",
      "Training loss: 2.3985\tTraining acc: 62.00%\n",
      "Training loss: 2.3728\tTraining acc: 61.94%\n",
      "Training loss: 2.3477\tTraining acc: 62.03%\n",
      "Training loss: 2.3231\tTraining acc: 62.09%\n",
      "Training loss: 2.2991\tTraining acc: 62.06%\n",
      "Training loss: 2.2755\tTraining acc: 62.09%\n",
      "Training loss: 2.2525\tTraining acc: 62.11%\n",
      "Training loss: 2.2300\tTraining acc: 62.20%\n",
      "Training loss: 2.2079\tTraining acc: 62.29%\n",
      "Training loss: 2.1863\tTraining acc: 62.26%\n",
      "Training loss: 2.1651\tTraining acc: 62.29%\n",
      "Training loss: 2.1443\tTraining acc: 62.34%\n",
      "Training loss: 2.1240\tTraining acc: 62.49%\n",
      "Training loss: 2.1041\tTraining acc: 62.43%\n",
      "Training loss: 2.0845\tTraining acc: 62.49%\n",
      "Training loss: 2.0654\tTraining acc: 62.51%\n",
      "Training loss: 2.0466\tTraining acc: 62.40%\n",
      "Training loss: 2.0282\tTraining acc: 62.43%\n",
      "Training loss: 2.0101\tTraining acc: 62.49%\n",
      "Training loss: 1.9924\tTraining acc: 62.51%\n",
      "Training loss: 1.9750\tTraining acc: 62.49%\n",
      "Training loss: 1.9579\tTraining acc: 62.57%\n",
      "Training loss: 1.9412\tTraining acc: 62.69%\n",
      "Training loss: 1.9247\tTraining acc: 62.74%\n",
      "Training loss: 1.9086\tTraining acc: 62.89%\n",
      "Training loss: 1.8927\tTraining acc: 62.94%\n",
      "Training loss: 1.8772\tTraining acc: 62.94%\n",
      "Training loss: 1.8619\tTraining acc: 62.94%\n",
      "Training loss: 1.8469\tTraining acc: 63.00%\n",
      "Training loss: 1.8321\tTraining acc: 63.03%\n",
      "Training loss: 1.8176\tTraining acc: 63.09%\n",
      "Training loss: 1.8034\tTraining acc: 63.20%\n",
      "Training loss: 1.7894\tTraining acc: 63.31%\n",
      "Training loss: 1.7756\tTraining acc: 63.31%\n",
      "Training loss: 1.7621\tTraining acc: 63.31%\n",
      "Training loss: 1.7488\tTraining acc: 63.26%\n",
      "Training loss: 1.7357\tTraining acc: 63.34%\n",
      "Training loss: 1.7229\tTraining acc: 63.37%\n",
      "Training loss: 1.7102\tTraining acc: 63.31%\n",
      "Training loss: 1.6978\tTraining acc: 63.23%\n",
      "Training loss: 1.6855\tTraining acc: 63.23%\n",
      "Training loss: 1.6735\tTraining acc: 63.20%\n",
      "Training loss: 1.6616\tTraining acc: 63.31%\n",
      "Training loss: 1.6500\tTraining acc: 63.37%\n",
      "Training loss: 1.6385\tTraining acc: 63.40%\n",
      "Training loss: 1.6272\tTraining acc: 63.51%\n",
      "Training loss: 1.6161\tTraining acc: 63.57%\n",
      "Training loss: 1.6051\tTraining acc: 63.57%\n",
      "Training loss: 1.5943\tTraining acc: 63.57%\n",
      "Training loss: 1.5837\tTraining acc: 63.60%\n",
      "Training loss: 1.5733\tTraining acc: 63.66%\n",
      "Training loss: 1.5630\tTraining acc: 63.69%\n",
      "Training loss: 1.5528\tTraining acc: 63.63%\n",
      "Training loss: 1.5428\tTraining acc: 63.66%\n",
      "Training loss: 1.5330\tTraining acc: 63.69%\n",
      "Training loss: 1.5233\tTraining acc: 63.74%\n",
      "Training loss: 1.5137\tTraining acc: 63.80%\n",
      "Training loss: 1.5043\tTraining acc: 63.83%\n",
      "Training loss: 1.4950\tTraining acc: 63.91%\n",
      "Training loss: 1.4858\tTraining acc: 63.94%\n",
      "Training loss: 1.4768\tTraining acc: 63.94%\n",
      "Training loss: 1.4679\tTraining acc: 63.91%\n",
      "Training loss: 1.4592\tTraining acc: 63.91%\n",
      "Training loss: 1.4505\tTraining acc: 63.97%\n",
      "Training loss: 1.4420\tTraining acc: 64.06%\n",
      "Training loss: 1.4336\tTraining acc: 64.14%\n",
      "Training loss: 1.4253\tTraining acc: 64.11%\n",
      "Training loss: 1.4171\tTraining acc: 64.14%\n",
      "Training loss: 1.4090\tTraining acc: 64.11%\n",
      "Training loss: 1.4010\tTraining acc: 64.17%\n",
      "Training loss: 1.3932\tTraining acc: 64.20%\n",
      "Training loss: 1.3854\tTraining acc: 64.23%\n",
      "Training loss: 1.3778\tTraining acc: 64.26%\n",
      "Training loss: 1.3702\tTraining acc: 64.34%\n",
      "Training loss: 1.3628\tTraining acc: 64.37%\n",
      "Training loss: 1.3554\tTraining acc: 64.34%\n",
      "Training loss: 1.3482\tTraining acc: 64.34%\n",
      "Training loss: 1.3410\tTraining acc: 64.34%\n",
      "Training loss: 1.3339\tTraining acc: 64.37%\n",
      "Training loss: 1.3269\tTraining acc: 64.37%\n",
      "Training loss: 1.3200\tTraining acc: 64.51%\n",
      "Training loss: 1.3132\tTraining acc: 64.63%\n",
      "Training loss: 1.3065\tTraining acc: 64.66%\n",
      "Training loss: 1.2998\tTraining acc: 64.69%\n",
      "Training loss: 1.2933\tTraining acc: 64.74%\n",
      "Training loss: 1.2868\tTraining acc: 64.77%\n",
      "Training loss: 1.2804\tTraining acc: 64.74%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.2741\tTraining acc: 64.80%\n",
      "Training loss: 1.2678\tTraining acc: 64.83%\n",
      "Training loss: 1.2616\tTraining acc: 64.86%\n",
      "Training loss: 1.2555\tTraining acc: 64.97%\n",
      "Training loss: 1.2495\tTraining acc: 64.97%\n",
      "Training loss: 1.2435\tTraining acc: 65.06%\n",
      "Training loss: 1.2376\tTraining acc: 65.09%\n",
      "Training loss: 1.2318\tTraining acc: 65.06%\n",
      "Training loss: 1.2261\tTraining acc: 65.14%\n",
      "Training loss: 1.2204\tTraining acc: 65.14%\n",
      "Training loss: 1.2148\tTraining acc: 65.11%\n",
      "Training loss: 1.2092\tTraining acc: 65.17%\n",
      "Training loss: 1.2037\tTraining acc: 65.11%\n",
      "Training loss: 1.1983\tTraining acc: 65.06%\n",
      "Training loss: 1.1929\tTraining acc: 65.09%\n",
      "Training loss: 1.1876\tTraining acc: 65.14%\n",
      "Training loss: 1.1823\tTraining acc: 65.14%\n",
      "Training loss: 1.1771\tTraining acc: 65.26%\n",
      "Training loss: 1.1720\tTraining acc: 65.31%\n",
      "Training loss: 1.1669\tTraining acc: 65.34%\n",
      "Training loss: 1.1618\tTraining acc: 65.37%\n",
      "Training loss: 1.1569\tTraining acc: 65.43%\n",
      "Training loss: 1.1519\tTraining acc: 65.49%\n",
      "Training loss: 1.1471\tTraining acc: 65.49%\n",
      "Training loss: 1.1422\tTraining acc: 65.46%\n",
      "Training loss: 1.1375\tTraining acc: 65.49%\n",
      "Training loss: 1.1328\tTraining acc: 65.69%\n",
      "Training loss: 1.1281\tTraining acc: 65.63%\n",
      "Training loss: 1.1235\tTraining acc: 65.60%\n",
      "Training loss: 1.1189\tTraining acc: 65.66%\n",
      "Training loss: 1.1143\tTraining acc: 65.77%\n",
      "Training loss: 1.1099\tTraining acc: 65.86%\n",
      "Training loss: 1.1054\tTraining acc: 65.91%\n",
      "Training loss: 1.1010\tTraining acc: 65.91%\n",
      "Training loss: 1.0967\tTraining acc: 65.89%\n",
      "Training loss: 1.0924\tTraining acc: 65.91%\n",
      "Training loss: 1.0881\tTraining acc: 65.94%\n",
      "Training loss: 1.0839\tTraining acc: 65.97%\n",
      "Training loss: 1.0797\tTraining acc: 65.94%\n",
      "Training loss: 1.0756\tTraining acc: 66.00%\n",
      "Training loss: 1.0715\tTraining acc: 66.03%\n",
      "Training loss: 1.0674\tTraining acc: 66.03%\n",
      "Training loss: 1.0634\tTraining acc: 66.09%\n",
      "Training loss: 1.0594\tTraining acc: 66.09%\n",
      "Training loss: 1.0555\tTraining acc: 66.11%\n",
      "Training loss: 1.0515\tTraining acc: 66.14%\n",
      "Training loss: 1.0477\tTraining acc: 66.20%\n",
      "Training loss: 1.0438\tTraining acc: 66.23%\n",
      "Training loss: 1.0400\tTraining acc: 66.37%\n",
      "Training loss: 1.0363\tTraining acc: 66.37%\n",
      "Training loss: 1.0325\tTraining acc: 66.37%\n",
      "Training loss: 1.0289\tTraining acc: 66.43%\n",
      "Training loss: 1.0252\tTraining acc: 66.46%\n",
      "Training loss: 1.0216\tTraining acc: 66.46%\n",
      "Training loss: 1.0180\tTraining acc: 66.49%\n",
      "Training loss: 1.0144\tTraining acc: 66.54%\n",
      "Training loss: 1.0109\tTraining acc: 66.54%\n",
      "Training loss: 1.0074\tTraining acc: 66.60%\n",
      "Training loss: 1.0039\tTraining acc: 66.66%\n",
      "Training loss: 1.0005\tTraining acc: 66.69%\n",
      "Training loss: 0.9971\tTraining acc: 66.74%\n",
      "Training loss: 0.9937\tTraining acc: 66.77%\n",
      "Training loss: 0.9903\tTraining acc: 66.80%\n",
      "Training loss: 0.9870\tTraining acc: 66.86%\n",
      "Training loss: 0.9837\tTraining acc: 66.86%\n",
      "Training loss: 0.9804\tTraining acc: 66.86%\n",
      "Training loss: 0.9772\tTraining acc: 66.80%\n",
      "Training loss: 0.9740\tTraining acc: 66.89%\n",
      "Training loss: 0.9708\tTraining acc: 67.00%\n",
      "Training loss: 0.9677\tTraining acc: 67.09%\n",
      "Training loss: 0.9645\tTraining acc: 67.06%\n",
      "Training loss: 0.9614\tTraining acc: 67.09%\n",
      "Training loss: 0.9584\tTraining acc: 67.14%\n",
      "Training loss: 0.9553\tTraining acc: 67.14%\n",
      "Training loss: 0.9523\tTraining acc: 67.11%\n",
      "Training loss: 0.9493\tTraining acc: 67.09%\n",
      "Training loss: 0.9463\tTraining acc: 67.09%\n",
      "Training loss: 0.9433\tTraining acc: 67.09%\n",
      "Training loss: 0.9404\tTraining acc: 67.09%\n",
      "Training loss: 0.9375\tTraining acc: 67.03%\n",
      "Training loss: 0.9346\tTraining acc: 67.09%\n",
      "Training loss: 0.9318\tTraining acc: 67.09%\n",
      "Training loss: 0.9289\tTraining acc: 67.17%\n",
      "Training loss: 0.9261\tTraining acc: 67.17%\n",
      "Training loss: 0.9233\tTraining acc: 67.20%\n",
      "Training loss: 0.9205\tTraining acc: 67.29%\n",
      "Training loss: 0.9178\tTraining acc: 67.31%\n",
      "Training loss: 0.9151\tTraining acc: 67.37%\n",
      "Training loss: 0.9123\tTraining acc: 67.29%\n",
      "Training loss: 0.9097\tTraining acc: 67.34%\n",
      "Training loss: 0.9070\tTraining acc: 67.40%\n",
      "Training loss: 0.9043\tTraining acc: 67.43%\n",
      "Training loss: 0.9017\tTraining acc: 67.51%\n",
      "Training loss: 0.8991\tTraining acc: 67.49%\n",
      "Training loss: 0.8965\tTraining acc: 67.49%\n",
      "Training loss: 0.8939\tTraining acc: 67.60%\n",
      "Training loss: 0.8914\tTraining acc: 67.60%\n",
      "Training loss: 0.8889\tTraining acc: 67.63%\n",
      "Training loss: 0.8864\tTraining acc: 67.66%\n",
      "Training loss: 0.8839\tTraining acc: 67.66%\n",
      "Training loss: 0.8814\tTraining acc: 67.69%\n",
      "Training loss: 0.8789\tTraining acc: 67.71%\n",
      "Training loss: 0.8765\tTraining acc: 67.66%\n",
      "Training loss: 0.8741\tTraining acc: 67.66%\n",
      "Training loss: 0.8717\tTraining acc: 67.74%\n",
      "Training loss: 0.8693\tTraining acc: 67.71%\n",
      "Training loss: 0.8669\tTraining acc: 67.77%\n",
      "Training loss: 0.8645\tTraining acc: 67.77%\n",
      "Training loss: 0.8622\tTraining acc: 67.77%\n",
      "Training loss: 0.8599\tTraining acc: 67.71%\n",
      "Training loss: 0.8576\tTraining acc: 67.69%\n",
      "Training loss: 0.8553\tTraining acc: 67.69%\n",
      "Training loss: 0.8530\tTraining acc: 67.74%\n",
      "Training loss: 0.8508\tTraining acc: 67.77%\n",
      "Training loss: 0.8485\tTraining acc: 67.83%\n",
      "Training loss: 0.8463\tTraining acc: 67.80%\n",
      "Training loss: 0.8441\tTraining acc: 67.83%\n",
      "Training loss: 0.8419\tTraining acc: 67.91%\n",
      "Training loss: 0.8397\tTraining acc: 67.91%\n",
      "Training loss: 0.8375\tTraining acc: 67.94%\n",
      "Training loss: 0.8354\tTraining acc: 67.97%\n",
      "Training loss: 0.8332\tTraining acc: 67.94%\n",
      "Training loss: 0.8311\tTraining acc: 68.00%\n",
      "Training loss: 0.8290\tTraining acc: 68.06%\n",
      "Training loss: 0.8269\tTraining acc: 68.11%\n",
      "Training loss: 0.8248\tTraining acc: 68.14%\n",
      "Training loss: 0.8227\tTraining acc: 68.14%\n",
      "Training loss: 0.8207\tTraining acc: 68.17%\n",
      "Training loss: 0.8186\tTraining acc: 68.17%\n",
      "Training loss: 0.8166\tTraining acc: 68.26%\n",
      "Training loss: 0.8146\tTraining acc: 68.23%\n",
      "Training loss: 0.8126\tTraining acc: 68.20%\n",
      "Training loss: 0.8106\tTraining acc: 68.26%\n",
      "Training loss: 0.8086\tTraining acc: 68.29%\n",
      "Training loss: 0.8067\tTraining acc: 68.31%\n",
      "Training loss: 0.8047\tTraining acc: 68.34%\n",
      "Training loss: 0.8028\tTraining acc: 68.31%\n",
      "Training loss: 0.8008\tTraining acc: 68.29%\n",
      "Training loss: 0.7989\tTraining acc: 68.20%\n",
      "Training loss: 0.7970\tTraining acc: 68.14%\n",
      "Training loss: 0.7951\tTraining acc: 68.06%\n",
      "Training loss: 0.7932\tTraining acc: 68.06%\n",
      "Training loss: 0.7914\tTraining acc: 68.11%\n",
      "Training loss: 0.7895\tTraining acc: 68.11%\n",
      "Training loss: 0.7877\tTraining acc: 68.14%\n",
      "Training loss: 0.7858\tTraining acc: 68.17%\n",
      "Training loss: 0.7840\tTraining acc: 68.14%\n",
      "Training loss: 0.7822\tTraining acc: 68.14%\n",
      "Training loss: 0.7804\tTraining acc: 68.14%\n",
      "Training loss: 0.7786\tTraining acc: 68.11%\n",
      "Training loss: 0.7768\tTraining acc: 68.14%\n",
      "Training loss: 0.7750\tTraining acc: 68.14%\n",
      "Training loss: 0.7733\tTraining acc: 68.14%\n",
      "Training loss: 0.7715\tTraining acc: 68.11%\n",
      "Training loss: 0.7698\tTraining acc: 68.14%\n",
      "Training loss: 0.7681\tTraining acc: 68.14%\n",
      "Training loss: 0.7664\tTraining acc: 68.14%\n",
      "Training loss: 0.7646\tTraining acc: 68.17%\n",
      "Training loss: 0.7629\tTraining acc: 68.14%\n",
      "Training loss: 0.7613\tTraining acc: 68.20%\n",
      "Training loss: 0.7596\tTraining acc: 68.20%\n",
      "Training loss: 0.7579\tTraining acc: 68.20%\n",
      "Training loss: 0.7562\tTraining acc: 68.26%\n",
      "Training loss: 0.7546\tTraining acc: 68.26%\n",
      "Training loss: 0.7530\tTraining acc: 68.26%\n",
      "Training loss: 0.7513\tTraining acc: 68.29%\n",
      "Training loss: 0.7497\tTraining acc: 68.29%\n",
      "Training loss: 0.7481\tTraining acc: 68.31%\n",
      "Training loss: 0.7465\tTraining acc: 68.40%\n",
      "Training loss: 0.7449\tTraining acc: 68.37%\n",
      "Training loss: 0.7433\tTraining acc: 68.37%\n",
      "Training loss: 0.7417\tTraining acc: 68.37%\n",
      "Training loss: 0.7401\tTraining acc: 68.40%\n",
      "Training loss: 0.7386\tTraining acc: 68.40%\n",
      "Training loss: 0.7370\tTraining acc: 68.46%\n",
      "Training loss: 0.7355\tTraining acc: 68.46%\n",
      "Training loss: 0.7339\tTraining acc: 68.46%\n",
      "Training loss: 0.7324\tTraining acc: 68.43%\n",
      "Training loss: 0.7309\tTraining acc: 68.40%\n",
      "Training loss: 0.7294\tTraining acc: 68.43%\n",
      "Training loss: 0.7279\tTraining acc: 68.46%\n",
      "Training loss: 0.7264\tTraining acc: 68.49%\n",
      "Training loss: 0.7249\tTraining acc: 68.54%\n",
      "Training loss: 0.7234\tTraining acc: 68.57%\n",
      "Training loss: 0.7220\tTraining acc: 68.60%\n",
      "Training loss: 0.7205\tTraining acc: 68.60%\n",
      "Training loss: 0.7190\tTraining acc: 68.57%\n",
      "Training loss: 0.7176\tTraining acc: 68.57%\n",
      "Training loss: 0.7162\tTraining acc: 68.57%\n",
      "Training loss: 0.7147\tTraining acc: 68.60%\n",
      "Training loss: 0.7133\tTraining acc: 68.63%\n",
      "Training loss: 0.7119\tTraining acc: 68.66%\n",
      "Training loss: 0.7105\tTraining acc: 68.74%\n",
      "Training loss: 0.7091\tTraining acc: 68.69%\n",
      "Training loss: 0.7077\tTraining acc: 68.69%\n",
      "Training loss: 0.7063\tTraining acc: 68.77%\n",
      "Training loss: 0.7049\tTraining acc: 68.80%\n",
      "Training loss: 0.7035\tTraining acc: 68.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7021\tTraining acc: 68.86%\n",
      "Training loss: 0.7008\tTraining acc: 68.91%\n",
      "Training loss: 0.6994\tTraining acc: 68.89%\n",
      "Training loss: 0.6981\tTraining acc: 68.89%\n",
      "Training loss: 0.6967\tTraining acc: 68.91%\n",
      "Training loss: 0.6954\tTraining acc: 68.91%\n",
      "Training loss: 0.6941\tTraining acc: 68.94%\n",
      "Training loss: 0.6928\tTraining acc: 68.91%\n",
      "Training loss: 0.6915\tTraining acc: 68.91%\n",
      "Training loss: 0.6901\tTraining acc: 68.86%\n",
      "Training loss: 0.6888\tTraining acc: 68.86%\n",
      "Training loss: 0.6875\tTraining acc: 68.86%\n",
      "Training loss: 0.6863\tTraining acc: 68.86%\n",
      "Training loss: 0.6850\tTraining acc: 68.83%\n",
      "Training loss: 0.6837\tTraining acc: 68.77%\n",
      "Training loss: 0.6824\tTraining acc: 68.77%\n",
      "Training loss: 0.6812\tTraining acc: 68.80%\n",
      "Training loss: 0.6799\tTraining acc: 68.86%\n",
      "Training loss: 0.6787\tTraining acc: 68.89%\n",
      "Training loss: 0.6774\tTraining acc: 68.97%\n",
      "Training loss: 0.6762\tTraining acc: 69.00%\n",
      "Training loss: 0.6749\tTraining acc: 69.00%\n",
      "Training loss: 0.6737\tTraining acc: 68.91%\n",
      "Training loss: 0.6725\tTraining acc: 68.94%\n",
      "Training loss: 0.6713\tTraining acc: 68.94%\n",
      "Training loss: 0.6701\tTraining acc: 69.06%\n",
      "Training loss: 0.6689\tTraining acc: 69.06%\n",
      "Training loss: 0.6677\tTraining acc: 69.11%\n",
      "Training loss: 0.6665\tTraining acc: 69.11%\n",
      "Training loss: 0.6653\tTraining acc: 69.09%\n",
      "Training loss: 0.6641\tTraining acc: 69.11%\n",
      "Training loss: 0.6629\tTraining acc: 69.11%\n",
      "Training loss: 0.6617\tTraining acc: 69.14%\n",
      "Training loss: 0.6606\tTraining acc: 69.17%\n",
      "Training loss: 0.6594\tTraining acc: 69.20%\n",
      "Training loss: 0.6583\tTraining acc: 69.17%\n",
      "Training loss: 0.6571\tTraining acc: 69.20%\n",
      "Training loss: 0.6560\tTraining acc: 69.23%\n",
      "Training loss: 0.6548\tTraining acc: 69.34%\n",
      "Training loss: 0.6537\tTraining acc: 69.37%\n",
      "Training loss: 0.6526\tTraining acc: 69.40%\n",
      "Training loss: 0.6514\tTraining acc: 69.43%\n",
      "Training loss: 0.6503\tTraining acc: 69.43%\n",
      "Training loss: 0.6492\tTraining acc: 69.43%\n",
      "Training loss: 0.6481\tTraining acc: 69.43%\n",
      "Training loss: 0.6470\tTraining acc: 69.40%\n",
      "Training loss: 0.6459\tTraining acc: 69.34%\n",
      "Training loss: 0.6448\tTraining acc: 69.37%\n",
      "Training loss: 0.6437\tTraining acc: 69.40%\n",
      "Training loss: 0.6426\tTraining acc: 69.40%\n",
      "Training loss: 0.6415\tTraining acc: 69.40%\n",
      "Training loss: 0.6405\tTraining acc: 69.40%\n",
      "Training loss: 0.6394\tTraining acc: 69.43%\n",
      "Training loss: 0.6383\tTraining acc: 69.43%\n",
      "Training loss: 0.6372\tTraining acc: 69.46%\n",
      "Training loss: 0.6362\tTraining acc: 69.46%\n",
      "Training loss: 0.6351\tTraining acc: 69.51%\n",
      "Training loss: 0.6341\tTraining acc: 69.51%\n",
      "Training loss: 0.6330\tTraining acc: 69.57%\n",
      "Training loss: 0.6320\tTraining acc: 69.60%\n",
      "Training loss: 0.6310\tTraining acc: 69.54%\n",
      "Training loss: 0.6299\tTraining acc: 69.57%\n",
      "Training loss: 0.6289\tTraining acc: 69.54%\n",
      "Training loss: 0.6279\tTraining acc: 69.54%\n",
      "Training loss: 0.6269\tTraining acc: 69.57%\n",
      "Training loss: 0.6259\tTraining acc: 69.57%\n",
      "Training loss: 0.6249\tTraining acc: 69.57%\n",
      "Training loss: 0.6238\tTraining acc: 69.60%\n",
      "Training loss: 0.6228\tTraining acc: 69.57%\n",
      "Training loss: 0.6218\tTraining acc: 69.54%\n"
     ]
    }
   ],
   "source": [
    "def grad_descent_MSE(w, b, X, y, alpha, epochs, reg, error_tol, validData=None, validTarget=None, testData=None, testTarget=None):\n",
    "    train_loss, train_acc = [], []\n",
    "    valid_loss, valid_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "    printing = True\n",
    "    for i in range(epochs):\n",
    "        grad_w, grad_b = gradMSE(w, b, X, y, reg)\n",
    "        w -= alpha * grad_w\n",
    "        b -= alpha * grad_b\n",
    "        \n",
    "        # Calculating Statistics\n",
    "        train_loss.append( MSE(w, b, X, y, reg) )\n",
    "        train_acc.append( accuracy(w, b, X, y) )\n",
    "\n",
    "        if validData != None and validTarget != None:\n",
    "            valid_loss.append( MSE(w, b, validData, validTarget, reg) )\n",
    "            valid_acc.append( accuracy(w, b, validData, validTarget) )\n",
    "        if testData != None and testTarget != None:\n",
    "            test_loss.append( MSE(w, b, testData, testTarget, reg) )\n",
    "            test_acc.append( accuracy(w, b, testData, testTarget) )\n",
    "        \n",
    "        # Print Losses and Accurancies if printing is on\n",
    "        if printing:\n",
    "            print(f\"Training loss: {train_loss[-1]:.4f}\\tTraining acc: {train_acc[-1]*100:.2f}%\")\n",
    "            if validData != None and validTarget != None:\n",
    "                print(f\"Validation loss: {valid_loss[-1]:.4f}\\tValidation acc: {valid_acc[-1]*100:.2f}%\")\n",
    "            if testData != None and testTarget != None:\n",
    "                print(f\"Testing loss: {test_loss[-1]:.4f}\\tTesting acc: {test_acc[-1]*100:.2f}%\")\n",
    "\n",
    "        # Check stopping condition\n",
    "        if i > 1 and np.abs(train_loss[-2] - train_loss[-1]) <= error_tol:\n",
    "            break\n",
    "\n",
    "    statistics = (train_loss, train_acc)\n",
    "    if validData != None and validTarget != None:\n",
    "        statistics += (valid_loss, valid_acc, )\n",
    "    if testData != None and testTarget != None:\n",
    "        statistics += (test_loss, test_acc,)\n",
    "    # Python 3.8 made this easier, but 3.7 you have to do this\n",
    "    out = (w, b, *statistics)\n",
    "    \n",
    "    return out\n",
    "\n",
    "X = trainData\n",
    "N = X.shape[0]\n",
    "d = X.shape[1] * X.shape[2]\n",
    "\n",
    "w = np.random.random_sample(d)\n",
    "b = np.random.random_sample(1)\n",
    "w, b, *statistics = grad_descent_MSE(w, b, trainData, trainTarget, 0.005, 5000, 0, 0.001)\n",
    "#train_loss, train_acc, valid_loss, valid_acc, test_loss, test_acc = statistics\n",
    "train_loss, train_acc = statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tuning the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplot_loss(np.arange(0, len(train_loss), 1), train_loss)#, valid_loss, test_loss)\\nplot_accuracy(np.arange(0, len(train_loss), 1), train_acc)#, valid_acc, test_acc)\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions to plot loss and accuracy\n",
    "def plot_loss(x, train_loss=None, valid_loss=None, test_loss=None, title=None, subplot=False):\n",
    "    if subplot:\n",
    "        plt.subplot(1, 2, 1)\n",
    "    if train_loss != None:\n",
    "        plt.plot(x, train_loss, label=\"Training Loss\")\n",
    "    if valid_loss != None:\n",
    "        plt.plot(x, valid_loss, label=\"Validation Loss\")\n",
    "    if test_loss != None:\n",
    "        plt.plot(x, test_loss, label=\"Testing Loss\")\n",
    "    \n",
    "    if title == None:\n",
    "        plt.title(\"Loss\")\n",
    "    else:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "def plot_accuracy(x, train_accuracy=None, valid_accuracy=None, test_accuracy=None, title=None, subplot=False):\n",
    "    if subplot:\n",
    "        plt.subplot(1, 2, 2)\n",
    "    if train_accuracy != None:\n",
    "        plt.plot(x, train_accuracy, label=\"Training Accuracy\")\n",
    "    if valid_accuracy != None:\n",
    "        plt.plot(x, valid_accuracy, label=\"Validation Accuracy\")\n",
    "    if test_accuracy != None:\n",
    "        plt.plot(x, test_accuracy, label=\"Testing Accuracy\")\n",
    "    \n",
    "    if title == None:\n",
    "        plt.title(\"Accuracy\")\n",
    "    else:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "    plt.grid(linestyle='-', axis='y')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "\"\"\"\n",
    "plot_loss(np.arange(0, len(train_loss), 1), train_loss)#, valid_loss, test_loss)\n",
    "plot_accuracy(np.arange(0, len(train_loss), 1), train_acc)#, valid_acc, test_acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your implementation of Gradient Descent with 5000 epochs and \\lambda = 0. Investigate the\n",
    "# impact of learning rate, \\alpha = 0.005, 0.001, 0.0001 on the performance of your classifier. \n",
    "# Plot the training, validation and test losses.\n",
    "\n",
    "# Eric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate impact by modifying the regularization parameter, \\lambda = {0.001, 0.1, 0.5}. \n",
    "# Plot the training, validation and test loss for \\alpha = 0:005 and report the final training, \n",
    "# validation and test accuracy of your classifier.\n",
    "\n",
    "# Sandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Comparing Batch GD with normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares Training loss: 0.0187\tLeast Squares Training acc: 71.29%\n",
      "Least Squares Validation loss: 0.0476\tLeast Squares Validation acc: 69.00%\n",
      "Least Squares Testing loss: 0.0570\tLeast Squares Testing acc: 66.90%\n"
     ]
    }
   ],
   "source": [
    "def least_squares(X, y):\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1] * X.shape[2]\n",
    "    X, _ = augment(X, np.zeros(X.shape[0]), 0)\n",
    "    y = y.reshape(-1)\n",
    "    \n",
    "    # overparameterized (deep learning)\n",
    "    if N < d:\n",
    "        w_aug = X.T.dot(np.linalg.inv( np.dot(X, X.T) )).dot(y)\n",
    "    # underparameterized (typical case)\n",
    "    else:\n",
    "        w_aug = np.linalg.inv( X.T @ X ) @ X.T @ y\n",
    "    \n",
    "    return w_aug[1:], w_aug[0]\n",
    "        \n",
    "# compare above to gradient descent solution\n",
    "w_LS, b_LS = least_squares(trainData, trainTarget)\n",
    "\n",
    "loss = MSE(w_LS, b_LS, trainData, trainTarget, 0)\n",
    "acc = accuracy(w_LS, b_LS, trainData, trainTarget)\n",
    "print(f\"Least Squares Training loss: {loss:.4f}\\tLeast Squares Training acc: {100*acc:.2f}%\")\n",
    "loss = MSE(w_LS, b_LS, validData, validTarget, 0)\n",
    "acc = accuracy(w_LS, b_LS, validData, validTarget)\n",
    "print(f\"Least Squares Validation loss: {loss:.4f}\\tLeast Squares Validation acc: {100*acc:.2f}%\")\n",
    "loss = MSE(w_LS, b_LS, testData, testTarget, 0)\n",
    "acc = accuracy(w_LS, b_LS, testData, testTarget)\n",
    "print(f\"Least Squares Testing loss: {loss:.4f}\\tLeast Squares Testing acc: {100*acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the analytical solution, the training loss achieved with the analytical equation is 0.0187 with a training accuracy of 71.29%. The training loss and accuracies for batch gradient descent were respectively 0.6918 and 67.97%. From the values, we see that the analytical solution performed better. However, computing it grows increasingly difficult with the size of the problem. As the problem scales, batch gradient descent allows for faster convergence with comparable accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Logistic Regression\n",
    "## 2.1 Binary cross-entropy loss\n",
    "### 1. Loss Function and Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Test that the CE function works\\nfrom sklearn.metrics import log_loss\\n\\nX = trainData\\ny = trainTarget\\nN = X.shape[0]\\nd = X.shape[1] * X.shape[2]\\n\\nw = np.random.random_sample(d)\\nb = np.random.random_sample(1)\\n\\ny_pred = sigmoid(predict(w_LS, b_LS, X))\\nprint(log_loss(y, y_pred))\\nprint(crossEntropyLoss(w_LS, b_LS, X, y, 0))\\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will work for both scalar and vector z\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "    \n",
    "\n",
    "# Cross Entropy Loss\n",
    "def crossEntropyLoss(w, b, X, y, reg):    \n",
    "    X, w = augment(X, w, b)\n",
    "    y = y.reshape(-1)\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    y_hat = sigmoid(X.dot(w))\n",
    "    \n",
    "    return 1.0/N * (-y.dot(np.log(y_hat)) - (1 - y).dot(np.log(1 - y_hat))) + reg/2.0 * np.square(w[1:]).sum()\n",
    "    \n",
    "\n",
    "def gradCE(w, b, X, y, reg):\n",
    "    X, w = augment(X, w, b)\n",
    "    y = y.reshape(-1)\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    y_hat = sigmoid(X.dot(w))\n",
    "    \n",
    "    w_grad = 1.0 /N * X.T.dot(y_hat - y) + reg * w\n",
    "    \n",
    "    return w_grad[1:], w_grad[0] - reg * w[0]\n",
    "\n",
    "\"\"\"\n",
    "# Test that the CE function works\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "X = trainData\n",
    "y = trainTarget\n",
    "N = X.shape[0]\n",
    "d = X.shape[1] * X.shape[2]\n",
    "\n",
    "w = np.random.random_sample(d)\n",
    "b = np.random.random_sample(1)\n",
    "\n",
    "y_pred = sigmoid(predict(w_LS, b_LS, X))\n",
    "print(log_loss(y, y_pred))\n",
    "print(crossEntropyLoss(w_LS, b_LS, X, y, 0))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE DOWN ANALYTICAL EXPRESSIONS OF LOSS AND GRADIENT\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}^{(n)} = \\sigma(W^T\\textbf{x}^{(n)} + b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{N}\\sum_{n=1}^{N} \\left [ -y^{(n)} \\log(\\hat{y}^{(n)}) -(1- y^{(n)}) \\log (1 - \\hat{y}^{(n)} ) \\right ] + \\frac{\\lambda}{2} \\Vert W \\Vert^2_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{b}} = \\frac{1}{N} \\sum_{n=1}^{N} \\left [ \\hat{y}^{(n)} - y^{(n)} \\right ]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W} = \\frac{1}{N} \\sum_{n=1}^{N} \\left [ (\\hat{y}^{(n)} - y^{(n)}) \\ \\textbf{x}^{(n)} \\right ]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def grad_descent(w, b, X, y, alpha, epochs, reg, error_tol, lossType=\"MSE\", validData=None, validTarget=None,\n",
    "                 testData=None, testTarget=None):\n",
    "    loss_func, grad_func = None, None\n",
    "    if lossType == \"MSE\":\n",
    "        loss_func, grad_func = MSE, gradMSE\n",
    "    elif lossType == \"CE\":\n",
    "        loss_func, grad_func = crossEntropyLoss, gradCE\n",
    "    else:\n",
    "        raise ValueError(\"Variable 'lossType' must be either 'MSE' or 'CE'.\")\n",
    "    train_loss, train_acc = [], []\n",
    "    valid_loss, valid_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "    printing = False\n",
    "    for i in range(epochs):\n",
    "        grad_w, grad_b = grad_func(w, b, X, y, reg)\n",
    "        w -= alpha * grad_w\n",
    "        b -= alpha * grad_b\n",
    "\n",
    "        # Calculating Statistics\n",
    "        train_loss.append(loss_func(w, b, X, y, reg))\n",
    "        train_acc.append(accuracy(w, b, X, y))\n",
    "\n",
    "        if validData is not None and validTarget is not None:\n",
    "            valid_loss.append(loss_func(w, b, validData, validTarget, reg))\n",
    "            valid_acc.append(accuracy(w, b, validData, validTarget))\n",
    "        if testData is not None and testTarget is not None:\n",
    "            test_loss.append(loss_func(w, b, testData, testTarget, reg))\n",
    "            test_acc.append(accuracy(w, b, testData, testTarget))\n",
    "\n",
    "        # Print Losses and Accurancies if printing is on\n",
    "        if printing:\n",
    "            print(f\"Training loss: {train_loss[-1]:.4f}\\tTraining acc: {train_acc[-1] * 100:.2f}%\")\n",
    "            if validData is not None and validTarget is not None:\n",
    "                print(f\"Validation loss: {valid_loss[-1]:.4f}\\tValidation acc: {valid_acc[-1] * 100:.2f}%\")\n",
    "            if testData is not None and testTarget is not None:\n",
    "                print(f\"Testing loss: {test_loss[-1]:.4f}\\tTesting acc: {test_acc[-1] * 100:.2f}%\")\n",
    "\n",
    "        # Check stopping condition\n",
    "        if i > 1 and np.abs(train_loss[-2] - train_loss[-1]) <= error_tol:\n",
    "            break\n",
    "\n",
    "    statistics = (train_loss, train_acc)\n",
    "    if validData is not None and validTarget is not None:\n",
    "        statistics += (valid_loss, valid_acc,)\n",
    "    if testData is not None and testTarget is not None:\n",
    "        statistics += (test_loss, test_acc,)\n",
    "    out = (w, b, *statistics)\n",
    "\n",
    "    return out\n",
    "        \n",
    "X = trainData\n",
    "N = X.shape[0]\n",
    "d = X.shape[1] * X.shape[2]\n",
    "\n",
    "w = np.random.random_sample(d)\n",
    "w = w - w.mean()\n",
    "b = np.random.random_sample(1)\n",
    "w, b, *statistics = grad_descent(w, b, trainData, trainTarget, 0.005, 5000, 0.1, 0.0001, \"CE\", validData, validTarget, testData, testTarget)\n",
    "train_loss, train_acc, valid_loss, valid_acc, test_loss, test_acc = statistics\n",
    "#train_loss, train_acc = statistics\n",
    "\n",
    "plot_loss(np.arange(0, len(train_loss), 1), train_loss, valid_loss, test_loss, subplot=False)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plot_accuracy(np.arange(0, len(train_loss), 1), train_acc, valid_acc, test_acc, subplot=False)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# oops, I (Dev) kinda started doing this one by mistake. All that's left is the plotting of the curves\n",
    "# Eric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparision to Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For zero weight decay, learning rate of 0.005 and 5000 epochs, \n",
    "# plot the training cross entropy loss and MSE loss for \n",
    "# logistic regression and linear regression respectively.\n",
    "# Comment on the effect of cross-entropy loss convergence behaviour.\n",
    "\n",
    "# Sandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Batch Gradient Descent vs. SGD and Adam\n",
    "## 3.1 SGD\n",
    "### 1. Building the Computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildGraph(loss=\"MSE\"):\n",
    "    #Initialize weight and bias tensors\n",
    "    tf.set_random_seed(421)\n",
    "\n",
    "    if loss == \"MSE\":\n",
    "        # Your implementation\n",
    "        pass\n",
    "    elif loss == \"CE\":\n",
    "        #Your implementation here\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Variable 'lossType' must be either 'MSE' or 'CE'.\")\n",
    "\n",
    "# Come back to this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementing Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the SGD algorithm for a minibatch size of 500 \n",
    "# optimizing over 700 epochs 2, minimizing the MSE (you will repeat this for the CE later).\n",
    "# Calculate the total number of batches required by dividing the number\n",
    "# of training instances by the minibatch size. After each epoch you will need to reshuffle the\n",
    "# training data and start sampling from the beginning again. Initially, set \\lambda = 0 and continue\n",
    "# to use the same \\alpha value (i.e. 0.001). After each epoch, store the training, validation and test\n",
    "# losses and accuracies. Use these to plot the loss and accuracy curves.\n",
    "\n",
    "# Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Batch Size Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cross Entropy Loss Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparison against Batch GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
